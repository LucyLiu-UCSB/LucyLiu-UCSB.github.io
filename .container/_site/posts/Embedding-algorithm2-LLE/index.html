<!DOCTYPE html><html lang="en"> <!-- The Head © 2017-2019 Cotes Chung MIT License --><head><title>Embedding algorithms 2 -- Locally linear embedding | Lucy's Blog</title><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v3.8.6" /><meta property="og:title" content="Embedding algorithms 2 – Locally linear embedding" /><meta name="author" content="Lucy Liu" /><meta property="og:locale" content="en_US" /><meta name="description" content="Introduction" /><meta property="og:description" content="Introduction" /><link rel="canonical" href="http://localhost:4000/posts/Embedding-algorithm2-LLE/" /><meta property="og:url" content="http://localhost:4000/posts/Embedding-algorithm2-LLE/" /><meta property="og:site_name" content="Lucy’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-12-27T19:11:00-08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Embedding algorithms 2 – Locally linear embedding" /><meta name="twitter:site" content="@LucyLiu84049511" /><meta name="twitter:creator" content="@Lucy Liu" /><meta name="google-site-verification" content="828U5Odxo38lGZ7ca6xyIc_r3oCovf3Xsr-XyShs3Ek" /> <script type="application/ld+json"> {"description":"Introduction","@type":"BlogPosting","headline":"Embedding algorithms 2 – Locally linear embedding","dateModified":"2019-12-28T18:28:30-08:00","datePublished":"2019-12-27T19:11:00-08:00","url":"http://localhost:4000/posts/Embedding-algorithm2-LLE/","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/Embedding-algorithm2-LLE/"},"author":{"@type":"Person","name":"Lucy Liu"},"@context":"https://schema.org"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/main.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script> document.jQuery || document.write('<script src="/assets/lib/jquery-3.4.1.min.js"><\/script>'); </script> <script src="https://cdn.jsdelivr.net/npm/popper.js@1.15.0/dist/umd/popper.min.js" integrity="sha256-fTuUgtT7O2rqoImwjrhDgbXTKUwyxxujIMRIK7TbuNU=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha256-5+02zu5UULQkO7w1GIr6vftCgMfFdZcAHeDtFnKZsBs=" crossorigin="anonymous"></script> <script src="/assets/js/dist/commons.js" async></script> <script src="/assets/js/dist/timeago.min.js"></script><link rel="stylesheet" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.css" /> <script src="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script> <script src="/assets/js/dist/toc.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar © 2017-2019 Cotes Chung MIT License --><div id="nav-wrap"><div id="profile-wrap" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/Lucy.png"></img> </a></div><div class="profile-text mt-3"><div id="site-title"> <a href="/">Lucy's Blog</a></div><div id="site-subtitle" class="font-italic">Learning for the sake of Learning</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-3 mr-4 hidden"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-3 mr-4 hidden"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-3 mr-4 hidden"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-3 mr-4 hidden"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-3 mr-4 hidden"></i> <span>ABOUT</span> </a></li></ul></div><div class="contact d-flex justify-content-around mt-4"> <a href="https://github.com/LucyLiu-UCSB" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/LucyLiu84049511" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href="javascript:window.open('mailto:' + ['xiliu','ucsb.edu'].join('@'))"> <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" target="_blank"> <i class="fas fa-rss"></i> </a></div></div><div id="main-wrap"> <!-- The Top Bar © 2017-2019 Cotes Chung MIT License --><div id="topbar" class="bg-white row justify-content-center topbar-down"><div id="topbar-main" class="d-flex h-100 align-items-center justify-content-between col-12 col-md-12 col-lg-11 col-xl-11 pl-md-2 pr-md-2 pl-lg-2 pr-lg-2"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Embedding algorithms 2 -- Locally linear embedding</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrap"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> </span> <a href="javascript:;">Cancel</a></div></div><div id="main"><div class="row justify-content-center bg-white"> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --> <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> <!-- Define the liquid date formats. © 2019 Cotes Chung Published under the MIT License --><div class="col-12 col-lg-11 col-xl-8"><div id="post-wrap" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4 pl-xl-3"><div class="post"><h1 data-toc-skip>Embedding algorithms 2 -- Locally linear embedding</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="timeago" data-toggle="tooltip" title="Fri, Dec 27, 2019, 7:11 PM -0800"> Dec 27, 2019 <i class="hidden">2019-12-27T19:11:00-08:00</i> </span> on <a href='/categories/manifold-learning/'>Manifold Learning</a>, <a href='/categories/embedding-methods/'>Embedding methods</a></div><div> Updated <span class="timeago lastmod" data-toggle="tooltip" title="Sat, Dec 28, 2019, 6:28 PM -0800"> Dec 28, 2019 <i class="hidden">2019-12-28T18:28:30-08:00</i> </span></div></div><div class="post-content"><h2 id="introduction">Introduction</h2><p>In the last post, though the nonclassical/metric MDS is a nonlinear embedding algorithm, it is a <em>global</em> method (like PCA) since each point in the graph is related to all other \(n-1\) points in the reconstruction step. Locally linear embedding (LLE) is fundamentally different from those global methods. Essentially, when reconstructing the lower dimensional coordinates for one point, only the neighborhood information of this point is used. Put another way, the embedding is optimized to preserve the local configurations of the nearest neighbors.</p><p>Below is a one-dimensional manifold lying in two-dimensional Euclidean space. The geometric structure can be embedded into a one-dimensional global coordinate– a straight line. However, we will see PCA as well as MDS ( remember they are equivalent in this case) will fail to learn the coordinate on the straight line.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s">'seaborn-whitegrid'</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">x_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">201</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">201</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
<span class="n">y_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">201</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">201</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
<span class="n">colorize</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">201</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s">'jet'</span><span class="p">,</span> <span class="mi">201</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_vec</span><span class="p">,</span> <span class="n">y_vec</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>  <span class="o">**</span><span class="n">colorize</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="/assets/img/sample/swirl_LLE.png" alt="swirl" width="400" class="center" /></p><p>PCA can not capture the intrinsic nonlinear relationship in a swirl as we can see different color overlap with each other.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x_vec</span><span class="p">,</span> <span class="n">y_vec</span><span class="p">]</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_pca</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">200</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">**</span><span class="n">colorize</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="/assets/img/sample/PCA_LLE.png" alt="PCA" width="400" class="center" /></p><h2 id="algorithm">Algorithm</h2><p>The LLE algorithm has three steps:</p><p><strong>Input:</strong></p><ul><li>\(n\times D\) high-dimensional matrix \(\mathbf{X}\),</li><li>an integer \(k\) used in the \(k\)-NN algorithm to define neighbors,</li><li>the desired output dimension \(d\), where \(k\geq d+1\).</li></ul><p><strong>LLE algorithm:</strong></p><ol><li>For each \(\mathbf{x}_i\), find the \(k\) nearest neighbors.</li><li>Find the weight matirx \(\mathbf{W}\), which preserve the linear local information of each point.</li><li>Compute \(\mathbf{Y}\) which best fits the local pattern defined by the weight matrix \(\mathbf{W}\).</li></ol><p><strong>Output:</strong></p><ul><li>\(n\times d\) low-dimensional matrix \(\mathbf{Y}\), which preserve the intrinsic coordinates of each point.</li></ul><h2 id="step-1-find-nearest-neighbors">Step 1. Find nearest neighbors</h2><p>The most commonly used algorithm to define a neighborhood is \(k\)-NN algorithm. An alternative method can be using a \(r\)-units ball. Essentially, \(k\) is a tuning parameter that governs trade-off between having enough points in each region (so as to deal with noise) and having small enough regions (to keep the linear approximation good.) In the summary paper written by Saul and Roweis, \(k\) has been set from 4 to 24. And they argued that in a range of \(k\) values, the performance of LLE should be stable and generally good.</p><p>Another crux is the relationship between \(k, d\) and \(D\). One definite relationship is \(d&lt;D\) so we call LLE is a dimension reduction method.</p><ul><li>\(k \geq d+1\). The reason of this requirment is the \(k\) neighbors span a space of dimensionality at most \(k - 1\). Therefore, it is impossiable to use information less than \(d\) dimensions to construct \(d\)-dimensional points. Also, it was recommended that some margin between \(d\) and \(k\) is generally necessary to obtain a topology-preserving embedding.</li><li>\(k\) can be greater or smaller than \(D\).<ol><li>\(k &gt; D\) indicating the original data is low dimensional. Each point can be reconstructed perfectly from its neighbors, and the weights are no longer uniquely defined. Just think about we have \(D\) equations but \(k, k &gt; D\), unknowns, so the solution is not unique. In this case, some regularization must be added to break the degeneracy.</li><li>\(k &lt; D\) is the usual case.</li></ol></li></ul><h2 id="step-2-find-weights">Step 2. Find Weights</h2><p>The <em>linearity</em> of LLE comes form the weight finding step. For each point \(\mathbf{x}_i\), it is defined as a linear combination of its neighbors.</p><script type="math/tex; mode=display">\mathbf{x}_i=\sum_jw_{ij}\mathbf{x}_j.</script><p>Then the weights are the optimizer of the cost function:</p><script type="math/tex; mode=display">L(\mathbf{w}_{ij}, j = 1,\ldots, n) = ||\mathbf{x}_i-\sum_jw_{ij}\mathbf{x}_j||^{2} + \alpha\sum_jw^{2}_{ij}.</script><p>The second term in the cost function is the \(L_2\) regularizor, which encourages equal weights. The above optimization problem is subject to two constraints:</p><ol><li>sparseness: if \(\mathbf{x}_{j}\) is out of the neighborhood of \(\mathbf{x}_i\), then \(w_{ij} = 0\).</li><li>invariance constraint: the local structure in the neighborhood should be invariance to translation, rotations and rescalings. Hence, \(\sum_j w_{ij} = 1\).</li></ol><p>Indeed, the weigh finding step can be broken into \(n\) subproblems. Each is a least sqaure question subject to the sum to one condition, which could be easily solved by formulating a Lagrange multiplier question.</p><h2 id="step-3-find-coordinates">Step 3. Find coordinates</h2><p>After finding the weight matrix \(\mathbf{W}\), it is used to represent the geometric information in \(\mathbf{X}\) so that \(\mathbf{X}\) does not appear in the final reconstruction step. The goal in this step is to find out \(n\times d, \mathbf{Y},\) matrix which minimizes</p><script type="math/tex; mode=display">\Phi(\mathbf{Y}) =\sum_i||\mathbf{y}_i -\sum_{j\neq i}w_{ij}\mathbf{y}_j||^{2}.</script><p>To break the degeneracy/make the optimization identifiable, the following assumptions are added:</p><ol><li>\(\mathbf{Y}\) has column mean 0, i.e. \(\sum_i\mathbf{y}_{ij} = 0\).</li><li>\(\mathbf{Y}\) is an orthogonal matrix subject to a scaling factor, i.e. \(\frac{1}{n}\mathbf{Y}^T\mathbf{Y} = \mathbf{I}_d.\)</li></ol><p>Since the geometric structure should be invariant under rotation, transformation (+/- constant), and homogeneously rescale the outputs, we can always make the covariance of \(\mathbf{Y}\) to be diagonal though the diagonal entris might be differ. The extra assumption is all the embedding coordinates should be of the same order.</p><p>The main difference between step 2 and step 3 is that step 3 is a global question so that the optimization question can not be seperated into small questions. It turns out the constrained optimization question is equivalent to find the smallest \(d+1\) eigenvector of a semipositive definite matrix. \[\Phi(\mathbf{Y}) = ||\mathbf{Y} - \mathbf{WY}||^2 = \text{trace}([(\mathbf{I} - \mathbf{W})\mathbf{Y}]^T[(\mathbf{I} - \mathbf{W})\mathbf{Y}]) = \text{trace}(\mathbf{Y}^T\mathbf{M}\mathbf{Y}).\]</p><p>First \(\mathbf{M}\) is a semipositive definite matrix and has 0 as an eigenvalue with \(\mathbf{1}\) as the corresponding eigenvector.</p><p>\[(\mathbf{I} - \mathbf{W})^T(\mathbf{I} - \mathbf{W})\mathbf{1} = (\mathbf{I} - \mathbf{W})^T(\mathbf{1} - \mathbf{1}) = 0 \text{ because of } \sum_jw_{ij} = 1.\]</p><p>Now form the Lagrange question \[L(\mathbf{Y}, \mu) = \text{trace}(\mathbf{Y}^T\mathbf{M}\mathbf{Y}) - \mu_1(\mathbf{Y}_1^T\mathbf{Y}_1 - n)-\ldots - \mu_d(\mathbf{Y}_d^T\mathbf{Y}_d - n).\] Take the first detivative with respect to \(\mathbf{Y}_i\), the ith column of \(\mathbf{Y}\), and set to be 0, \[\frac{\partial L(\mathbf{Y}, \mu)}{\mathbf{Y}_i} = 2 \mathbf{MY}_i - 2\mu_i\mathbf{Y}_i = 0.\] Finally, we get \(\mathbf{MY}_i = \mu_i \mathbf{Y}_i\). Thus, in order to minimize \(\Phi(\mathbf{Y})\), \(\mathbf{Y}_i\) should be the \(i+1\)th smallest eigenvector of \(\mathbf{M}\). Besides, the eigenvectors are orthogonal to each other and \(\mathbf{Y}_i\mathbf{1} = 0\) since \(\mathbf{1}\) is the eigenvector of eigenvalue 0, which means the columns of \(\mathbf{Y}\) have mean 0.</p><h2 id="implement-in-python">Implement in Python</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">LocallyLinearEmbedding</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LocallyLinearEmbedding</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">'modified'</span><span class="p">,</span>
                               <span class="n">eigen_solver</span><span class="o">=</span><span class="s">'dense'</span><span class="p">)</span>
<span class="n">lle_res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lle_res</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">200</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">**</span><span class="n">colorize</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="/assets/img/sample/lle_swirl.png" alt="lle_s" width="400" class="center" /></p><p>As we can see, the order of color in the above map is align with the color in swirl. So the linearity in a swirl is perfectly learned by LLE.</p><h2 id="reference">Reference:</h2><ol><li><a href="https://www.stat.cmu.edu/~cshalizi/350/lectures/14/lecture-14.pdf">CMU data mining lecture notes: Nonlinear Dimensionality Reduction I: Local Linear Embedding</a></li><li><a href="http://www.jmlr.org/papers/volume4/saul03a/saul03a.pdf">Think Globally, Fit Locally: Unsupervised Learning of Low Dimensional Manifolds</a></li></ol></div><div class="post-tail text-muted"><div class="mb-4"> <a href="/tags/manifold/" class="post-tag no-text-decoration" >Manifold</a>&ensp; <a href="/tags/embedding/" class="post-tag no-text-decoration" >Embedding</a></div></div></div><!-- The related posts of current post. Placed in the bottom of every single post. © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-4 mb-4 pb-3"><h3 class="pt-2 mt-1 mb-4" data-toc-skip>Related Posts</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Embedding-algorithm1-MDS/"><div class="card-body"> <span class="timeago small"> Dec 10, 2019 <i class="hidden">2019-12-10T19:27:00-08:00</i> </span><h3 class="pt-0 mt-2 mb-3" data-toc-skip>Embedding algorithms 1 -- Multidimensional scaling</h3><div class="text-muted small"><p>Manifold learning is a class of unsupervised estimators that seeks to describe datasets as low-dimensional manifolds embedded in high-dimensional spaces. Some linear dimension reduction methods ar...</p></div></div></a></div><div class="card"> <a href="/posts/math-definition-of-manifold/"><div class="card-body"> <span class="timeago small"> Dec 10, 2019 <i class="hidden">2019-12-10T17:07:00-08:00</i> </span><h3 class="pt-0 mt-2 mb-3" data-toc-skip>Mathematical definition of Manifold</h3><div class="text-muted small"><p>The machine learning community has borrowed lots of terminologies from mathematics. To gain a deeper understanding of the feature learning/dimension reduction approaches, I make some notes of the r...</p></div></div></a></div></div></div><div class="post-pager d-flex justify-content-between"> <a href="/posts/Asterisk-in-Python/" class="btn btn-outline-primary"> <i class="fas fa-angle-left mr-1"></i> OLDER POST </a> <a href="/posts/Sort-multiple-variables/" class="btn btn-outline-primary"> NEWER POST <i class="fas fa-angle-right ml-1"></i> </a></div><!-- The Disqus lazy loading. Powered by: https://osvaldas.info/lazy-loading-disqus-comments © 2019 Cotes Chung MIT License --><div id="disqus" class="pt-2 pb-4"><p class="font-italic text-muted small">Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/assets/lib/jquery.disqusloader.min.js"></script> <script> var options = { scriptUrl: '//LucyLiu.disqus.com/embed.js', disqusConfig: function() { this.page.url = 'http://localhost:4000/posts/Embedding-algorithm2-LLE/'; this.page.identifier = '/posts/Embedding-algorithm2-LLE/'; } }; $.disqusLoader('#disqus', options); </script></div></div><!-- The Pannel on right side (Desktop views) © 2017-2019 Cotes Chung MIT License --><div id="panel-wrap" class="col-xl-3 pl-2 topbar-down"><div class="access"><div id="access-lastmod" class="post mb-4""><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Sort-multiple-variables/">Sort multiple variables</a></li><li><a href="/posts/Some-useful-operations-in-MySQL-easy-level/">Some useful operations in MySQL--Easy level</a></li><li><a href="/posts/Embedding-algorithm2-LLE/">Embedding algorithms 2 -- Locally linear embedding</a></li><li><a href="/posts/Embedding-algorithm1-MDS/">Embedding algorithms 1 -- Multidimensional scaling</a></li><li><a href="/posts/Some-useful-operations-in-MySQL-median-level/">Some useful operations in MySQL--Median level</a></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/manifold/">Manifold</a> <a class="post-tag" href="/tags/embedding/">Embedding</a> <a class="post-tag" href="/tags/sql/">SQL</a> <a class="post-tag" href="/tags/recursion/">Recursion</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/statistics/">Statistics</a> <a class="post-tag" href="/tags/dynamic-programming/">Dynamic Programming</a> <a class="post-tag" href="/tags/divide&conquer/">Divide&Conquer</a> <a class="post-tag" href="/tags/directed-graph/">Directed Graph</a></div></div></div><div id="toc-wrap" class="pl-0 pr-4"><h3 data-toc-skip class="pl-3 pt-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><!-- The Footer © 2017-2019 Cotes Chung MIT License --><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="copyright"><p class="mb-0"> © 2019-2020<a href="https://twitter.com/LucyLiu84049511" class="ml-1">Lucy Liu</a>. <br>Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> & <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a>, hosted on <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.</p></div><div class="license"><p class="mb-0"> The blog posts on this site are licensed under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p></div></div></footer></div><!-- The Search results © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrap"><div class="row justify-content-center bg-white"><div class="col-12 col-md-12 col-lg-11 col-xl-9 pl-xl-5 pr-xl-5 pb-5 mt-3 mb-3"><h2 class="mt-3 pt-3 ml-3 ml-md-5 ml-lg-0" data-toc-skip>Search Results</h2><div class="post-content ml-1 ml-md-5 ml-lg-0"><ul id="search-results" ></ul></div></div></div></div></div><div id="mask"></div><!-- The Search © 2017-2019 Cotes Chung MIT License --> <script src="/assets/lib/simple-jekyll-search-1.7.1.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/search.json' }) </script> <a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a>
