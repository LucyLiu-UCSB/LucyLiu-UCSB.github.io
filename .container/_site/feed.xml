<feed xmlns="http://www.w3.org/2005/Atom"> <id>http://localhost:4000</id><title>Lucy's Blog</title><subtitle>Learning for the sake of Learning</subtitle> <updated>2020-01-06T17:47:04-08:00</updated> <author> <name>Lucy Liu</name> <uri>http://localhost:4000</uri> </author><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000" rel="alternate" type="text/html" /> <generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator> <rights> Â© 2020 Lucy Liu </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Multiple comparisons</title><link href="http://localhost:4000/posts/Multiple-comparisons/" rel="alternate" type="text/html" title="Multiple comparisons" /><published>2020-01-06T00:00:00-08:00</published> <updated>2020-01-06T17:47:04-08:00</updated> <id>http://localhost:4000/posts/Multiple-comparisons/</id> <content src="http://localhost:4000/posts/Multiple-comparisons/" /> <author> <name>Lucy Liu</name> </author> <category term="Technical Tools" /> <category term="Statistics" /> <summary>In statistics, multiple comparisons/multiple hypothesis testing occurs when one considers a set of statistical inference questions simultaneously. To control the chance of making mistakes when the ...</summary> </entry> <entry><title>Sort multiple variables</title><link href="http://localhost:4000/posts/Sort-multiple-variables/" rel="alternate" type="text/html" title="Sort multiple variables" /><published>2019-12-31T14:41:00-08:00</published> <updated>2020-01-06T17:47:04-08:00</updated> <id>http://localhost:4000/posts/Sort-multiple-variables/</id> <content src="http://localhost:4000/posts/Sort-multiple-variables/" /> <author> <name>Lucy Liu</name> </author> <category term="Technical Tools" /> <category term="Python programming" /> <summary>Usually, we are proficient at sorting the data frame/table by one variable. But there are cases that we need a second variable to break the ties. In this post, I will summarize how to do this in Py...</summary> </entry> <entry><title>Embedding algorithms 2 -- Locally linear embedding</title><link href="http://localhost:4000/posts/Embedding-algorithm2-LLE/" rel="alternate" type="text/html" title="Embedding algorithms 2 -- Locally linear embedding" /><published>2019-12-27T19:11:00-08:00</published> <updated>2020-01-06T17:47:04-08:00</updated> <id>http://localhost:4000/posts/Embedding-algorithm2-LLE/</id> <content src="http://localhost:4000/posts/Embedding-algorithm2-LLE/" /> <author> <name>Lucy Liu</name> </author> <category term="Manifold Learning" /> <category term="Embedding methods" /> <summary>Introduction In the last post, though the nonclassical/metric MDS is a nonlinear embedding algorithm, it is a global method (like PCA) since each point in the graph is related to all other \(n-1\)...</summary> </entry> <entry><title>Asterisk in Python</title><link href="http://localhost:4000/posts/Asterisk-in-Python/" rel="alternate" type="text/html" title="Asterisk in Python" /><published>2019-12-17T00:00:00-08:00</published> <updated>2020-01-06T17:47:04-08:00</updated> <id>http://localhost:4000/posts/Asterisk-in-Python/</id> <content src="http://localhost:4000/posts/Asterisk-in-Python/" /> <author> <name>Lucy Liu</name> </author> <category term="Technical Tools" /> <category term="Python programming" /> <summary>The use of * in python is related to the way of passing parameters to a function. First, in python, we have three types of parameters, Positional-or-Keyword Arguments, Positional-Only Parameters an...</summary> </entry> <entry><title>Embedding algorithms 1 -- Multidimensional scaling</title><link href="http://localhost:4000/posts/Embedding-algorithm1-MDS/" rel="alternate" type="text/html" title="Embedding algorithms 1 -- Multidimensional scaling" /><published>2019-12-10T19:27:00-08:00</published> <updated>2020-01-06T17:47:04-08:00</updated> <id>http://localhost:4000/posts/Embedding-algorithm1-MDS/</id> <content src="http://localhost:4000/posts/Embedding-algorithm1-MDS/" /> <author> <name>Lucy Liu</name> </author> <category term="Manifold Learning" /> <category term="Embedding methods" /> <summary>Manifold learning is a class of unsupervised estimators that seeks to describe datasets as low-dimensional manifolds embedded in high-dimensional spaces. Some linear dimension reduction methods ar...</summary> </entry> </feed>
