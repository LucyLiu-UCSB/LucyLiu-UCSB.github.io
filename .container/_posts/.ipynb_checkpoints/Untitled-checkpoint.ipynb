{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vanillaRNN:\n",
    "    def __init__(self, n_x, n_h, seq_length, learning_rate):\n",
    "        # hyperparameters\n",
    "        self.n_x = n_x\n",
    "        self.n_h = n_h\n",
    "        self.seq_length = seq_length\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # initialize model parameters\n",
    "        self.Wxh = np.random.randn(n_h, n_x) * 0.01\n",
    "        self.Whh = np.random.randn(n_h, n_h) * 0.01\n",
    "        self.Why = np.random.randn(n_x, n_h) * 0.01\n",
    "        self.bh = np.zeros((n_h, 1))\n",
    "        self.by = np.zeros((n_x, 1))\n",
    "        \n",
    "        # memory vars for adagrad\n",
    "        self.mWxh = np.zeros_like(self.Wxh)\n",
    "        self.mWhh = np.zeros_like(self.Whh)\n",
    "        self.mWhy = np.zeros_like(self.Why)\n",
    "        self.mbh = np.zeros_like(self.bh)\n",
    "        self.mby = np.zeros_like(self.by)\n",
    "        \n",
    "    def forward_pass(self, inputs, targets, hprev):\n",
    "        \"\"\"\n",
    "        inputs -- list of integers (tokenizer: char to int)\n",
    "        targets -- list of integers (tokenizer: char to int)\n",
    "        hprev -- the initial hidden state\n",
    "        \"\"\"\n",
    "        x, h, y, p = {}, {}, {}, {}\n",
    "        h[-1] = np.copy(hprev)\n",
    "        loss = 0\n",
    "    \n",
    "        for t in range(len(inputs)):\n",
    "            \n",
    "            # one hot encoder of a char\n",
    "            x[t] = np.zeros((n_x, 1))\n",
    "            x[t][inputs[t]] = 1\n",
    "            h[t] = np.tanh(self.Wxh @ x[t] + self.Whh @ h[t-1] + self.bh)\n",
    "            y[t] = self.Why @ h[t] + self.by\n",
    "            p[t] = np.exp(y[t]) / np.sum(np.exp(y[t]))\n",
    "            loss = loss - np.log(p[t][targets[t], 0])\n",
    "            \n",
    "        return loss, x, h, p\n",
    "    \n",
    "    def backpropagation(self, x, h, p, targets):\n",
    "        \n",
    "        dWxh, dWhy, dWhh = np.zeros_like(self.Wxh), np.zeros_like(self.Why), np.zeros_like(dWhh)\n",
    "        dbh, dby = np.zeros_like(self.bh), np.zeros_like(self.by)\n",
    "        dhnext = np.zeros_like(h[0])\n",
    "        \n",
    "        for t in reversed(range(self.seq_length)):\n",
    "            dy = np.copy(p[t])\n",
    "            dy[targets[t]] =  dy[targets[t]] - 1\n",
    "            dWhy = dWhy + dy @ h[t].T\n",
    "            dby = dby + dy\n",
    "            dh = Why.T @ dy + dhnext\n",
    "            dhraw = (1 - h[t] * h[t]) * dh\n",
    "            dbh = dbh + dhraw\n",
    "            dWxh = dWxh + dhraw @ x[t].T\n",
    "            dWhh = dWhh + dhraw @ h[t-1].T\n",
    "            dhnext = Whh.T @ dhraw\n",
    "        for dpara in [dWxh, dWhh, dWhy, dby, dbh]:\n",
    "            np.clip(dpara, -5, 5, out = dpara)\n",
    "            \n",
    "        return dWxh, dWhh, dWhy, dbh, dby\n",
    "    \n",
    "    def update_para(self, dWxh, dWhh, dWhy, dbh, dby):\n",
    "        for para, dpara, mem in zip([self.Wxh, self.Whh, self.Why, self.bh, self.by], \n",
    "                                    [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                    [self.mWxh, self.mWhh, self.mWhy, self.mbh, self.mby]):\n",
    "            mem = mem + dpara * dpara\n",
    "            para = para - self.learning_rate * dpara / np.sqrt(mem + 1e-8)\n",
    "            \n",
    "    def train(self, inputs, char_to_int, int_to_char, max_iter = 1e5):\n",
    "        \n",
    "        iter_num, p, n = 0, 0, 0\n",
    "        loss_list = []\n",
    "        loss_list.append(- np.log(1 / self.n_x) * self.seq_length)        \n",
    "        \n",
    "        while iter_num <= max_iter:\n",
    "            \n",
    "            ## reset the rnn after an epoch\n",
    "            if p + self.seq_length + 1 >= len(inputs) or n == 0:\n",
    "                hprev = np.zeros((self.n_h, 1))\n",
    "                p = 0\n",
    "                \n",
    "            ## chars to int\n",
    "            input_bacth = [char_to_int[ch] for ch in inputs[p:p + self.seq_length]]\n",
    "            target_bacth = [char_to_int[ch] for ch in inputs[p + 1 : p + self.seq_length + 1]]\n",
    "            \n",
    "            ## forward_pass\n",
    "            loss, x, h, p = self.forward_pass(input_bacth, target_bacth, hprev)\n",
    "            loss_list.append(loss_list[-1] * 0.999 + loss * 0.001)\n",
    "            ## backpropagation\n",
    "            dWxh, dWhh, dWhy, dbh, dby = self.backpropagation(x, h, p, target_bacth)\n",
    "            ## adagrad upate\n",
    "            self.update_para(dWxh, dWhh, dWhy, dbh, dby)\n",
    "            hprev = h[self.seq_length - 1]\n",
    "            \n",
    "            iter_num = iter_num + 1\n",
    "            \n",
    "        ## make a sample after training\n",
    "        sample_ix = self.make_sample(hprev, target_bacth[-1], 200)\n",
    "        sample_char = ''.join(int_to_char[ix] for ix in sample_ix)\n",
    "    return loss_list, sample_char\n",
    "\n",
    "            \n",
    "    def make_sample(self, hprev, seed_ix, n):\n",
    "        \"\"\"\n",
    "        sample a length n sequence from the model\n",
    "        \"\"\"\n",
    "        x = np.zeros((self.n_x, 1))\n",
    "        x[seed_ix] = 1\n",
    "        ixes = []\n",
    "        h = np.copy(hprev)\n",
    "        \n",
    "        for t in range(n):\n",
    "            h = np.tanh(self.Wxh @ x + self.Whh @ h + self.nh\n",
    "            y = self.Why @ h + self.by\n",
    "            p = np.exp(y) / np.sum(np.exp(y))\n",
    "            ix = np.random.choice(range(self.n_x), p = p.ravel())\n",
    "            x = np.zeros((self.n_x, 1))\n",
    "            x[ix] = 1\n",
    "            ixes.append(ix)\n",
    "        return ixes     \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
